{
 "cells": [
  {
   "cell_type": "code",
   "id": "5fa65546-9057-4aa7-9a41-e2c6822e79b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:18.152563Z",
     "start_time": "2024-12-11T01:19:18.150516Z"
    }
   },
   "source": [
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import joblib\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# import openpyxl\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "fdbc466c-553f-4718-94f1-0300a7d1c1fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:18.195727Z",
     "start_time": "2024-12-11T01:19:18.193903Z"
    }
   },
   "source": [
    "class DecisionTreeNode:\n",
    "    def __init__(self):\n",
    "        self.feature_index = None  # Index of the feature to split on\n",
    "        self.threshold = None  # Threshold value for splitting\n",
    "        self.left = None  # Left child node\n",
    "        self.right = None  # Right child node\n",
    "        self.value = None  # Prediction value (for leaf nodes)"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "id": "51e7dde1-e0d6-489d-9740-55d0ec7fa2a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:18.240292Z",
     "start_time": "2024-12-11T01:19:18.237495Z"
    }
   },
   "source": [
    "def mse(y):\n",
    "    \"\"\"Mean Squared Error.\"\"\"\n",
    "    return np.mean((y - np.mean(y)) ** 2)\n",
    "\n",
    "def mse_pred_gt(y_true, y_pred):\n",
    "    \"\"\"Mean Squared Error calculation.\"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "def split_data(X, y, feature_index, threshold):\n",
    "    \"\"\"Split the dataset based on a feature and threshold.\"\"\"\n",
    "    left_mask = X[:, feature_index] <= threshold\n",
    "    right_mask = ~left_mask\n",
    "    return X[left_mask], X[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "def best_split(X, y):\n",
    "    \"\"\"Find the best feature and threshold to split the data.\"\"\"\n",
    "    best_feature, best_threshold, best_mse = None, None, float('inf')\n",
    "    for feature_index in range(X.shape[1]):\n",
    "        thresholds = np.unique(X[:, feature_index])\n",
    "        for threshold in thresholds:\n",
    "            _, _, y_left, y_right = split_data(X, y, feature_index, threshold)\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue\n",
    "            mse_split = (len(y_left) * mse(y_left) + len(y_right) * mse(y_right)) / len(y)\n",
    "            if mse_split < best_mse:\n",
    "                best_feature, best_threshold, best_mse = feature_index, threshold, mse_split\n",
    "    return best_feature, best_threshold"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "id": "222d9038-294e-4e64-a055-cefa4de3af90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:18.283833Z",
     "start_time": "2024-12-11T01:19:18.281590Z"
    }
   },
   "source": [
    "def build_tree(X, y, depth=0, max_depth=5):\n",
    "    \"\"\"Build a decision tree recursively.\"\"\"\n",
    "    node = DecisionTreeNode()\n",
    "    if depth == max_depth or len(np.unique(y)) == 1:  # Stop splitting at max depth or pure leaf\n",
    "        node.value = np.mean(y)\n",
    "        return node\n",
    "\n",
    "    feature_index, threshold = best_split(X, y)\n",
    "    if feature_index is None:  # No valid split\n",
    "        node.value = np.mean(y)\n",
    "        return node\n",
    "\n",
    "    node.feature_index = feature_index\n",
    "    node.threshold = threshold\n",
    "    X_left, X_right, y_left, y_right = split_data(X, y, feature_index, threshold)\n",
    "    node.left = build_tree(X_left, y_left, depth + 1, max_depth)\n",
    "    node.right = build_tree(X_right, y_right, depth + 1, max_depth)\n",
    "    return node"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "54f05aea-d83c-4815-8037-2ae4263e50fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:18.327563Z",
     "start_time": "2024-12-11T01:19:18.325559Z"
    }
   },
   "source": [
    "def predict_tree(node, X):\n",
    "    \"\"\"Predict with a single decision tree.\"\"\"\n",
    "    # if node.value is not None:\n",
    "    #     return node.value\n",
    "    # if X[node.feature_index] <= node.threshold:\n",
    "    #     return predict_tree(node.left, X)\n",
    "    # return predict_tree(node.right, X)\n",
    "    if len(X.shape) == 1:  # Single row\n",
    "        if node.value is not None:  # Leaf node\n",
    "            return node.value\n",
    "        if X[node.feature_index] <= node.threshold:\n",
    "            return predict_tree(node.left, X)\n",
    "        else:\n",
    "            return predict_tree(node.right, X)\n",
    "    else:  # Batch of rows\n",
    "        return np.array([predict_tree(node, row) for row in X])\n"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "34204437-0840-4dd5-b82b-495ca4961da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:18.371729Z",
     "start_time": "2024-12-11T01:19:18.369288Z"
    }
   },
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=5, max_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features  # Number of random features to consider at each split\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the random forest.\"\"\"\n",
    "        for _ in range(self.n_trees):\n",
    "            # Bootstrap sample: Sample with replacement\n",
    "            indices = np.random.choice(len(X), int(len(X)*0.02), replace=True)\n",
    "            X_sample, y_sample = X[indices], y[indices]\n",
    "            # Train a decision tree on the sample\n",
    "            tree = build_tree(X_sample, y_sample, max_depth=self.max_depth)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict by averaging predictions from all trees.\"\"\"\n",
    "        # predictions = np.array([predict_tree(tree, x) for tree in self.trees for x in X])\n",
    "        tree_preds = np.array([predict_tree(tree, X) for tree in self.trees])\n",
    "        return np.mean(tree_preds, axis=0)\n",
    "        # return predictions.reshape(self.n_trees, len(X)).mean(axis=0)\n"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "id": "57c92d4f-57fa-4f8d-b3b0-f95448ed4c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:19.488952Z",
     "start_time": "2024-12-11T01:19:18.413287Z"
    }
   },
   "source": [
    "# load pre-processed data\n",
    "import os\n",
    "data_folder_fp = \"data_folder\"\n",
    "raw_data_fp = os.path.join(data_folder_fp, \"numpy_data.pt\")\n",
    "(X_train, X_val, X_test, y_train, y_val, y_test) = torch.load(raw_data_fp, weights_only=False)"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "id": "db763a4f-e38b-4496-8980-de618b2e989c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:19.496565Z",
     "start_time": "2024-12-11T01:19:19.495033Z"
    }
   },
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(type(X_train))\n",
    "print(type(y_train))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58271, 671) (58271,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "id": "d5248d9f-9035-4b02-80f9-3e02a5b52c23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:19.542391Z",
     "start_time": "2024-12-11T01:19:19.540703Z"
    }
   },
   "source": [
    "# X_train = X_train.to_numpy()  # Convert pandas DataFrame to NumPy array\n",
    "# y_train = y_train.to_numpy()  # Convert pandas Series to NumPy array"
   ],
   "outputs": [],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "id": "5337c6ef-ebe5-44ec-8baf-b9f36501f637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:19.585861Z",
     "start_time": "2024-12-11T01:19:19.584440Z"
    }
   },
   "source": [
    "rf = RandomForest(n_trees=10, max_depth=5)"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "id": "6e773e65-e724-402c-bdb9-b9143c84aa8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:19:19.631034Z",
     "start_time": "2024-12-11T01:19:19.628447Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize_heatmap(performance, n_trees_list, max_depth_list, image_folder, title=\"Validation MSE\", filename=\"rf_performance_heatmap.jpg\"):\n",
    "    # Generate heatmap visualization\n",
    "    performance_df = pd.DataFrame(\n",
    "        performance,\n",
    "        index=[f\"max_depth={d}\" for d in max_depth_list],\n",
    "        columns=[f\"n_trees={t}\" for t in n_trees_list],\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(\n",
    "        performance_df, annot=True, fmt=\".4f\", cmap=\"viridis\", cbar_kws={\"label\": title}\n",
    "    )\n",
    "    plt.title(f\"Random Forest Hyperparameter Tuning: {title}\")\n",
    "    plt.xlabel(\"Number of Trees\")\n",
    "    plt.ylabel(\"Maximum Depth\")\n",
    "\n",
    "    # Save the heatmap to the image folder\n",
    "    heatmap_fp = os.path.join(image_folder, filename)\n",
    "    plt.savefig(heatmap_fp)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "id": "215f147e-b70d-4a2a-b145-b89b88c00231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:48:07.355518Z",
     "start_time": "2024-12-11T01:48:07.351745Z"
    }
   },
   "source": [
    "def validate_rf(rf, X_val, y_val):\n",
    "    # Predict on the validation set\n",
    "    y_val_pred = rf.predict(X_val)\n",
    "    # Calculate validation MSE\n",
    "    val_loss = mse_pred_gt(y_val, y_val_pred)\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def train_rt(X_train, \n",
    "             y_train, \n",
    "             X_val, \n",
    "             y_val,\n",
    "             X_test,\n",
    "             y_test,\n",
    "             n_trees_list = [10, 50, 100], \n",
    "             max_depth_list =[15, 20],  \n",
    "             num_epochs=1,\n",
    "             model_folder=\"models/random_forest\",\n",
    "             image_folder=\"images/random_forest\"):\n",
    "\n",
    "    min_val_mse = float('inf')\n",
    "    # Training loop for Random Forest\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "\n",
    "    \n",
    "     # Initialize performance storage\n",
    "    performance = np.zeros((len(max_depth_list), len(n_trees_list)))\n",
    "    test_performance = np.zeros((len(max_depth_list), len(n_trees_list)))\n",
    "\n",
    "\n",
    "    # Loop over all combinations of n_trees and max_depth\n",
    "    for i, max_depth in enumerate(max_depth_list):\n",
    "        for j, n_trees in enumerate(n_trees_list):\n",
    "            # Build Random Forest model\n",
    "            rf = RandomForest(n_trees=n_trees, max_depth=max_depth)\n",
    "\n",
    "            # Train the Random Forest on the training set\n",
    "            rf.fit(X_train, y_train)\n",
    "\n",
    "            # Validate the model\n",
    "            val_loss = validate_rf(rf, X_val, y_val)\n",
    "            performance[i, j] = val_loss\n",
    "\n",
    "            # Test the model\n",
    "            y_test_pred = rf.predict(X_test)\n",
    "            test_loss = mse_pred_gt(y_test, y_test_pred)\n",
    "            test_performance[i, j] = test_loss\n",
    "\n",
    "            # Save the model for the current configuration\n",
    "            model_fp = os.path.join(\n",
    "                model_folder, f\"rf_{n_trees}_{max_depth}.pth\"\n",
    "            )\n",
    "            torch.save(rf, model_fp)\n",
    "\n",
    "            # Print progress\n",
    "            print(\n",
    "                f\"n_trees={n_trees}, max_depth={max_depth}: Val MSE = {val_loss:.4f}, Test MSE = {test_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "    # Call the visualization function for validation and test performance\n",
    "    visualize_heatmap(performance, n_trees_list, max_depth_list, image_folder, title=\"Validation MSE\", filename=\"rf_validation_performance_heatmap.jpg\")\n",
    "    visualize_heatmap(test_performance, n_trees_list, max_depth_list, image_folder, title=\"Test MSE\", filename=\"rf_test_performance_heatmap.jpg\")\n",
    "\n",
    "    return performance, test_performance"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "id": "2ce24b7a-4aaa-4afa-ba18-0be09e83aab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:55:49.919432Z",
     "start_time": "2024-12-11T01:48:23.949187Z"
    }
   },
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "model_folder=\"models/random_forest\"\n",
    "image_folder=\"images/random_forest\"\n",
    "import time\n",
    "start_time = time.time()\n",
    "train_performance, test_performance= train_rt(X_train, y_train, \n",
    "             X_val, \n",
    "             y_val,\n",
    "             X_test,\n",
    "             y_test,\n",
    "             model_folder=model_folder,\n",
    "             image_folder=image_folder)\n",
    "duration = time.time() - start_time\n",
    "print(f\"Training duration = {duration}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trees=10, max_depth=15: Val MSE = 11787.6729, Test MSE = 10645.1258\n",
      "n_trees=50, max_depth=15: Val MSE = 11407.8913, Test MSE = 10081.1329\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[93], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtime\u001B[39;00m\n\u001B[1;32m      7\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 8\u001B[0m train_performance, test_performance\u001B[38;5;241m=\u001B[39m \u001B[43mtrain_rt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m             \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m             \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m             \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m             \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m             \u001B[49m\u001B[43mmodel_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m             \u001B[49m\u001B[43mimage_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage_folder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m duration \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining duration = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mduration\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[92], line 39\u001B[0m, in \u001B[0;36mtrain_rt\u001B[0;34m(X_train, y_train, X_val, y_val, X_test, y_test, n_trees_list, max_depth_list, num_epochs, model_folder, image_folder)\u001B[0m\n\u001B[1;32m     36\u001B[0m rf \u001B[38;5;241m=\u001B[39m RandomForest(n_trees\u001B[38;5;241m=\u001B[39mn_trees, max_depth\u001B[38;5;241m=\u001B[39mmax_depth)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# Train the Random Forest on the training set\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m \u001B[43mrf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Validate the model\u001B[39;00m\n\u001B[1;32m     42\u001B[0m val_loss \u001B[38;5;241m=\u001B[39m validate_rf(rf, X_val, y_val)\n",
      "Cell \u001B[0;32mIn[84], line 15\u001B[0m, in \u001B[0;36mRandomForest.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     13\u001B[0m X_sample, y_sample \u001B[38;5;241m=\u001B[39m X[indices], y[indices]\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Train a decision tree on the sample\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m tree \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_tree\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_depth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_depth\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrees\u001B[38;5;241m.\u001B[39mappend(tree)\n",
      "Cell \u001B[0;32mIn[82], line 16\u001B[0m, in \u001B[0;36mbuild_tree\u001B[0;34m(X, y, depth, max_depth)\u001B[0m\n\u001B[1;32m     14\u001B[0m node\u001B[38;5;241m.\u001B[39mthreshold \u001B[38;5;241m=\u001B[39m threshold\n\u001B[1;32m     15\u001B[0m X_left, X_right, y_left, y_right \u001B[38;5;241m=\u001B[39m split_data(X, y, feature_index, threshold)\n\u001B[0;32m---> 16\u001B[0m node\u001B[38;5;241m.\u001B[39mleft \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_tree\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_left\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_left\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdepth\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_depth\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m node\u001B[38;5;241m.\u001B[39mright \u001B[38;5;241m=\u001B[39m build_tree(X_right, y_right, depth \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, max_depth)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m node\n",
      "Cell \u001B[0;32mIn[82], line 16\u001B[0m, in \u001B[0;36mbuild_tree\u001B[0;34m(X, y, depth, max_depth)\u001B[0m\n\u001B[1;32m     14\u001B[0m node\u001B[38;5;241m.\u001B[39mthreshold \u001B[38;5;241m=\u001B[39m threshold\n\u001B[1;32m     15\u001B[0m X_left, X_right, y_left, y_right \u001B[38;5;241m=\u001B[39m split_data(X, y, feature_index, threshold)\n\u001B[0;32m---> 16\u001B[0m node\u001B[38;5;241m.\u001B[39mleft \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_tree\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_left\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_left\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdepth\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_depth\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m node\u001B[38;5;241m.\u001B[39mright \u001B[38;5;241m=\u001B[39m build_tree(X_right, y_right, depth \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, max_depth)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m node\n",
      "Cell \u001B[0;32mIn[82], line 16\u001B[0m, in \u001B[0;36mbuild_tree\u001B[0;34m(X, y, depth, max_depth)\u001B[0m\n\u001B[1;32m     14\u001B[0m node\u001B[38;5;241m.\u001B[39mthreshold \u001B[38;5;241m=\u001B[39m threshold\n\u001B[1;32m     15\u001B[0m X_left, X_right, y_left, y_right \u001B[38;5;241m=\u001B[39m split_data(X, y, feature_index, threshold)\n\u001B[0;32m---> 16\u001B[0m node\u001B[38;5;241m.\u001B[39mleft \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_tree\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_left\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_left\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdepth\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_depth\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m node\u001B[38;5;241m.\u001B[39mright \u001B[38;5;241m=\u001B[39m build_tree(X_right, y_right, depth \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, max_depth)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m node\n",
      "Cell \u001B[0;32mIn[82], line 8\u001B[0m, in \u001B[0;36mbuild_tree\u001B[0;34m(X, y, depth, max_depth)\u001B[0m\n\u001B[1;32m      5\u001B[0m     node\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(y)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m node\n\u001B[0;32m----> 8\u001B[0m feature_index, threshold \u001B[38;5;241m=\u001B[39m \u001B[43mbest_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m feature_index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# No valid split\u001B[39;00m\n\u001B[1;32m     10\u001B[0m     node\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(y)\n",
      "Cell \u001B[0;32mIn[81], line 21\u001B[0m, in \u001B[0;36mbest_split\u001B[0;34m(X, y)\u001B[0m\n\u001B[1;32m     19\u001B[0m thresholds \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(X[:, feature_index])\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m threshold \u001B[38;5;129;01min\u001B[39;00m thresholds:\n\u001B[0;32m---> 21\u001B[0m     _, _, y_left, y_right \u001B[38;5;241m=\u001B[39m \u001B[43msplit_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_left) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_right) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     23\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "id": "6755945a-f21a-406b-a779-1f3a9860286e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:46:13.715433821Z",
     "start_time": "2024-12-11T00:50:12.099471Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fada96bc-97ee-4492-833d-8a59cee7daa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:55:54.845295Z",
     "start_time": "2024-12-11T01:55:54.842632Z"
    }
   },
   "source": [
    "def demo_rf_price(rf_model_fp, data_sample, categorical_features, numerical_features, encoder, scaler):\n",
    "    \"\"\"\n",
    "    Predict the sale price using a trained Random Forest model.\n",
    "\n",
    "    Parameters:\n",
    "        rf_model (RandomForest): Trained Random Forest model.\n",
    "        data_sample (dict): New sample data as a dictionary.\n",
    "        categorical_features (list): List of categorical feature names.\n",
    "        numerical_features (list): List of numerical feature names.\n",
    "        encoder (CustomOneHotEncoder): Fitted one-hot encoder for categorical features.\n",
    "        scaler (CustomStandardScaler): Fitted standard scaler for numerical features.\n",
    "    \"\"\"\n",
    "    # Convert the sample data to a DataFrame\n",
    "    data_sample_df = pd.DataFrame(data_sample)\n",
    "\n",
    "    # Apply one-hot encoding to categorical columns\n",
    "    new_data_cat = encoder.transform(data_sample_df[categorical_features])\n",
    "    \n",
    "    # Scale numerical columns\n",
    "    new_data_num = scaler.transform(data_sample_df[numerical_features])\n",
    "    \n",
    "    # Combine processed numerical and categorical features\n",
    "    new_data_processed = np.hstack([new_data_num, new_data_cat])\n",
    "\n",
    "    rf_model = torch.load(rf_model_fp, weights_only=False)\n",
    "    # Predict sale price using the Random Forest model\n",
    "    predicted_price = rf_model.predict(new_data_processed)\n",
    "\n",
    "    # Print the predicted sale price\n",
    "    print(f\"Predicted Sale Price: {predicted_price[0]:.2f}\")\n"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "id": "6b715264-3db3-461d-b051-cf60dc926b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:46:13.715771513Z",
     "start_time": "2024-12-11T00:50:12.150777Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c895ad2a-d52f-4cd3-ab91-b14356527646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:55:57.897872Z",
     "start_time": "2024-12-11T01:55:57.452312Z"
    }
   },
   "source": [
    "best_model_fp = \"models/random_forest/rf_100_20.pth\"\n",
    "# best_model_fp = \"training_mae_2000.pt\"\n",
    "categorical_features = ['Order Date', 'Brand', 'Sneaker Name', 'Release Date', 'Buyer Region']\n",
    "numerical_features = ['Retail Price', 'Shoe Size']\n",
    "\n",
    "new_data = {\n",
    "    'Order Date': ['2022-01-01'],\n",
    "    'Brand': ['Yeezy'],\n",
    "    'Sneaker Name': ['Adidas-Yeezy-Boost-350-V2-Core-Black-Red'],\n",
    "    'Retail Price': [220],\n",
    "    'Release Date': ['2018-02-11'],\n",
    "    'Shoe Size': [11.0],\n",
    "    'Buyer Region': ['California']\n",
    "}\n",
    "from utils import CustomOneHotEncoder, StandardScaler\n",
    "\n",
    "encoder_scaler_fp = os.path.join(data_folder_fp, \"encoder_scaler.pt\")\n",
    "encoder, scaler = torch.load(encoder_scaler_fp, weights_only=False)\n",
    "demo_rf_price(best_model_fp, new_data, categorical_features, numerical_features, encoder, scaler)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sale Price: 583.12\n"
     ]
    }
   ],
   "execution_count": 95
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
